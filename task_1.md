In this notebook, I have fist analysed the data and converted non-numerical features to numerical using Label Encoder.
I have then generated synthetic data using SMOTE to fix class imbalance and then using Standard Scaler, I have normalised the data. 


![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/48754733-2319-4402-9692-2de83b75b98c)


![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/8135f475-96e3-4e25-a809-ccba3039b02a)



Then I have used feature selection methods - Recursive Feature Elimination and Feature Selection using Correlation Matrix to select 6 most important features.



![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/c60742a6-2d04-4365-854d-917bdfb79378)



After this some EDA(Exploratory Data Analysis) to analyse distribution of features and performed Bivariate Analysis.



![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/efa6679d-9a6f-48bb-8d48-ce12a79ab49b)
![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/9d256ee4-3ee4-4d7e-94f4-9c6d612d5606)
![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/0b701526-fce8-467d-8bbc-232b0d71c1cf)
![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/3b8bc153-32fb-4b87-9265-b0778868ff7d)

![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/f50a56b6-1788-4df2-b93c-3a61232c063c)




Finally, I have built the model and trained it. And performed a comparison of the precision and F1 scores obtained. 



![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/88a8a8ed-b5a0-4d3f-9b20-f171be3f24a2)

![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/9904ce26-7beb-4fc7-8ff7-28baf9ad4fe8)

![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/a5f74c27-646e-42a5-a1a0-4833932b0308)

![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/83739f40-cb1c-497b-95e7-8f50302ae23a)

![image](https://github.com/SiddhAVR/Devcomm-task/assets/106260588/b0634192-69af-4d6e-a494-580e3790e56a)



